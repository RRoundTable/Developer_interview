## Auto Encoder에 대해서 아는대로 얘기하라

![autoencoder](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTNKtx8ZT2pv_AqjGTlgpVb4An7JlxAR-YVF3jY5TJqdXzTy7cG)

Auto Encoder는 input data를 더 낮은 차원으로 축소 시킨 후, 다시 복원하는 과정을 거친다. 

이때, 차원을 축소하는 이유는 input data를 구성하는 의미있는 요인을 학습하기 위해서 이다. 

학습하는 과정에서 사용하는 Loss function은 L2 loss이다.

input data와 reconstructed input data간의 l2 loss를 감소시키는 방향으로 학습한다. 이 때, input data는 labeling이 필요없다!

### MNIST AE를 TF나 Keras등으로 만든다면 몇줄일까

layer의 수에 따라 다소 차이는 있겠으나, 기본적인 구성은 다음과 같다.

1. import module

2. parameter(learning rate, batch_size, 등등)

3. layer 정의

4. encoder 함수 정의

5. decoder 함수 정의

6. loss 정의

7. 학습


- MNIST data

  class : 0,1,2,3,4,5,6,7,8,9
  
  input data dimension : 28*28 (data 하나 당)

### MNIST에 대해서 임베딩 차원을 1로 해도 학습이 될까?

'학습이 된다' 라는 것은 loss를 의미있게 줄여나갈 수 있냐는 질문으로 받아들이겠다.

이는 곧 1차원의 vector가 mnist의 data의 의미있는 feature를 추출할 수 있냐는 것인데,

1차원의 vector는 직선의 공간만 표현할 수 있다.
![dimension](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQzFvFpS-UdohQWvgmA5-v0bAOMwX9vlbmfihDYMfjdNEqbiR4x9)

이 정도의 정보량으로 decoder가 MNIST이미지를 복원할 수 있을 것인가?

-  우선 현실적으로는 불가능 할 것이라고 생각한다.

-  한가지 클래스만 가지고 학습하고, 정말 복잡하고 깊은 network로 이루어진 encoder, decoder라면, 가능할 것 같다. 
  [0]이라는 정보만으로, MNIST '0'의 이미지를 복원할 수 있을 것 같다. 그리고, 같은 '0'이어도 [0.002]이면 조금 찌그러진 0으로 표현할 수 있지 않을까 생각이 든다.

- 두 가지 이상의 class라면, 불가능 할 것이라고 생각한다.

위에 언급했듯이 하나의 class만을 학습시킨다면, 가능할 여지가 있다고 본다. 

하지만, class가 두 가지라면 이야기는 달라진다.0과 1 class가 있다고 가정해보자.

위에서는 [0.0002]가 0의 모양에 영향을 줄 수 있다고 했다. 하지만, [0.5]는 어떤 의미를 가질 것인가.

class 0과 1은 서로 유사한 형태라고 보기 힘들다. 둘은 continuous한 1차원 vector로 나타낸다면 많은 정보의 손실이 일어날 것이다.(의미가 없어질 만큼)


### 임베딩 차원을 늘렸을 때의 장단점은?

### AE 학습시 항상 Loss를 0으로 만들수 있을까?

### VAE는 무엇인가?
